{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7a582f-290f-4992-873e-0dacf999c71f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino usando cuda:0\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 3.2692 Acc: 0.2788\n",
      "val Loss: 1.7642 Acc: 0.5266\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9085 Acc: 0.5148\n",
      "val Loss: 1.0385 Acc: 0.6937\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.5563 Acc: 0.5861\n",
      "val Loss: 0.7798 Acc: 0.7652\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.3577 Acc: 0.6357\n",
      "val Loss: 0.6395 Acc: 0.8090\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.2268 Acc: 0.6654\n",
      "val Loss: 0.5897 Acc: 0.8217\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.1166 Acc: 0.6903\n",
      "val Loss: 0.4441 Acc: 0.8652\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.0365 Acc: 0.7214\n",
      "val Loss: 0.3780 Acc: 0.8859\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.8289 Acc: 0.7720\n",
      "val Loss: 0.1948 Acc: 0.9461\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.7136 Acc: 0.8132\n",
      "val Loss: 0.1630 Acc: 0.9559\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.6727 Acc: 0.8167\n",
      "val Loss: 0.1477 Acc: 0.9613\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.6635 Acc: 0.8207\n",
      "val Loss: 0.1352 Acc: 0.9645\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.8269\n",
      "val Loss: 0.1247 Acc: 0.9669\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.6239 Acc: 0.8270\n",
      "val Loss: 0.1175 Acc: 0.9702\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.5844 Acc: 0.8408\n",
      "val Loss: 0.1093 Acc: 0.9696\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.5631 Acc: 0.8490\n",
      "val Loss: 0.1069 Acc: 0.9701\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.5536 Acc: 0.8551\n",
      "val Loss: 0.1058 Acc: 0.9704\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.5805 Acc: 0.8446\n",
      "val Loss: 0.1048 Acc: 0.9712\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.5521 Acc: 0.8482\n",
      "val Loss: 0.1035 Acc: 0.9720\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.5494 Acc: 0.8473\n",
      "val Loss: 0.1026 Acc: 0.9723\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.5684 Acc: 0.8492\n",
      "val Loss: 0.1019 Acc: 0.9726\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.5454 Acc: 0.8532\n",
      "val Loss: 0.1006 Acc: 0.9730\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.5614 Acc: 0.8478\n",
      "val Loss: 0.1007 Acc: 0.9728\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.5482 Acc: 0.8547\n",
      "val Loss: 0.1006 Acc: 0.9726\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.5470 Acc: 0.8520\n",
      "val Loss: 0.1002 Acc: 0.9730\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.5482 Acc: 0.8510\n",
      "val Loss: 0.1006 Acc: 0.9729\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.5368 Acc: 0.8556\n",
      "val Loss: 0.1001 Acc: 0.9733\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.5418 Acc: 0.8520\n",
      "val Loss: 0.1003 Acc: 0.9730\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.5526 Acc: 0.8530\n",
      "val Loss: 0.0996 Acc: 0.9730\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.5358 Acc: 0.8570\n",
      "val Loss: 0.0996 Acc: 0.9733\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.5565 Acc: 0.8520\n",
      "val Loss: 0.0997 Acc: 0.9733\n",
      "\n",
      "Training complete in 22m 36s\n",
      "Best val Acc: 0.9733\n",
      "Modelo salvo em: efficientnet_model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Desativa todos os avisos\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Verificar se há GPU disponível\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Treino usando {device}')\n",
    "\n",
    "# Definir hiperparâmetros\n",
    "num_epochs = 30\n",
    "batch_size = 78\n",
    "learning_rate = 0.001\n",
    "data_dir = './images/'  # Substitua pelo caminho para suas pastas de imagens\n",
    "model_save_path = 'efficientnet_model.pth'\n",
    "\n",
    "# Transformações de dados\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomAffine(0, shear=20, scale=(0.8, 1.2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Carregar os dados\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Carregar o modelo EfficientNet pré-treinado\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "# Modificar a última camada para corresponder ao número de classes no seu conjunto de dados\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Definir a função de perda e o otimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Função para treinar o modelo\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Cada época tem uma fase de treino e validação\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Modo de treino\n",
    "            else:\n",
    "                model.eval()  # Modo de avaliação\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterar sobre os dados\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zerar os gradientes do otimizador\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + otimização somente na fase de treino\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Estatísticas\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Salvar o melhor modelo\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Carregar os melhores pesos do modelo\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# Treinar o modelo\n",
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs)\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print('Modelo salvo em:', model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317d816e-263a-46c1-a8bb-4d2eb6e17747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Função para processar a imagem\n",
    "def process_image(image):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = preprocess(image).unsqueeze(0)  # Adiciona uma dimensão para o batch\n",
    "    return image\n",
    "\n",
    "# Função para fazer a predição\n",
    "def predict(image_url, model, class_names):\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    image = process_image(image)\n",
    "    image = image.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predicted_class = class_names[preds[0]]\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Caminho para o modelo salvo\n",
    "model_save_path = 'efficientnet_model.pth'\n",
    "\n",
    "# Carregar o modelo e as classes\n",
    "model = EfficientNet.from_name('efficientnet-b0')\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, len(class_names))\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b11f26ff-fea6-44ad-b64f-8f799066515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: copo termico\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "image_url = 'https://d87n9o45kphpy.cloudfront.net/Custom/Content/Products/27/39/2739098_copo-termico-com-abridor-stz-metalizado-preto-5187641_l1_638259794366132214.jpg'  # Substitua pela URL da imagem\n",
    "predicted_class = predict(image_url, model, class_names)\n",
    "\n",
    "print('Predicted class:', predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a8fef-e99d-49ee-8c47-6746a9cf3a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
