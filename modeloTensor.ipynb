{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913c54f8-e912-4334-af46-8c594636ce6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 01:03:23.829577: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 01:03:24.686225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b5807b-851f-475b-8ad4-5dd932f6adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs das imagens para download\n",
    "image_urls ={\n",
    "    \"calcado_infantil\":[\n",
    "        \"https://images-americanas.b2w.io/produtos/5017625269/imagens/mordedor-bebe-maozinha-com-agua-alivio-gengiva-buba-baby/5017625357_1_large.jpg\"\n",
    "    ]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07362f16-1591-4533-aefe-397c51d1b584",
   "metadata": {},
   "source": [
    "Baixa um conjunto de imagens de exemplo (por exemplo, fotos de animais, frutas, veículos, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b910d6-cb7d-44d0-bbcb-02dd815ae86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando as imagens da categoria calcado_infantil\n"
     ]
    }
   ],
   "source": [
    "# Crie um diretório para armazenar as imagens baixadas\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "# Função para baixar imagens\n",
    "def download_images(urls):\n",
    "    for chave, lista in urls.items():\n",
    "        print(f\"Carregando as imagens da categoria {chave}\")\n",
    "        # Cria o diretório para a chave se ele não existir\n",
    "        os.makedirs(f'images/{chave}', exist_ok=True)\n",
    "        for i, url in enumerate(lista):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:  # Verifica se o download foi bem-sucedido\n",
    "                with open(f'images/{chave}/image_{i}.jpg', 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "            else:\n",
    "                print(f\"Falha ao baixar a imagem {url}\")\n",
    "\n",
    "\n",
    "# Baixe as imagens\n",
    "download_images(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd879455-57ff-4fec-96ed-c691f05c91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_display_images(main_folder, num_images=2):\n",
    "    for subdir in os.listdir(main_folder):\n",
    "        subdir_path = os.path.join(main_folder, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            print(f\"Exibindo imagens da subpasta: {subdir}\")\n",
    "            image_files = os.listdir(subdir_path)\n",
    "            for image_file in image_files[:num_images]:\n",
    "                img_path = os.path.join(subdir_path, image_file)\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    plt.imshow(img)\n",
    "                    plt.title(f'Categoria: {subdir}, Imagem: {image_file}')\n",
    "                    plt.axis('off') \n",
    "                    plt.show()\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao carregar a imagem {img_path}: {e}\")\n",
    "\n",
    "# Carregue e visualize as imagens baixadas\n",
    "load_and_display_images('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87bf868-604d-4dc1-9874-3258749a25f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_images(main_folder, target_size=(224, 224)):\n",
    "    processed_images = []\n",
    "    labels = []\n",
    "    for subdir in os.listdir(main_folder):\n",
    "        subdir_path = os.path.join(main_folder, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for image_file in os.listdir(subdir_path):\n",
    "                img_path = os.path.join(subdir_path, image_file)\n",
    "                try:\n",
    "                    img = Image.open(img_path).resize(target_size)\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB') \n",
    "                    img_array = np.array(img) / 255.0 \n",
    "                    if img_array.shape == (224, 224, 3): \n",
    "                        processed_images.append(img_array)\n",
    "                        labels.append(subdir)  # Usa o nome do subdiretório como rótulo\n",
    "                    else:\n",
    "                        print(f\"Imagem {img_path} tem forma incorreta: {img_array.shape}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao processar a imagem {img_path}: {e}\")\n",
    "    return np.array(processed_images), np.array(labels)\n",
    "\n",
    "# Pré-processamento das imagens\n",
    "processed_images, labels = preprocess_images('images')\n",
    "\n",
    "# Exibir as formas dos arrays processados\n",
    "print(f\"Processed images shape: {processed_images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# Codificação dos rótulos para números inteiros\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Número de classes\n",
    "num_classes = len(np.unique(encoded_labels))\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a59ca-7de5-409c-ae73-8b48408fd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_images, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definição do modelo CNN\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "######\n",
    "# Carregar o modelo ResNet50 pré-treinado\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Adicionar camadas ao modelo\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Congelar as camadas convolucionais do modelo base\n",
    "base_model.trainable = False\n",
    "###################\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinamento do modelo\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
    "\n",
    "# Avaliação do modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Previsão com o modelo treinado\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc85e5c-7150-4b0b-9dc3-326198bd11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Adicionar novas camadas de classificação\n",
    "x = base_model.output\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Criar o novo modelo\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Congelar as camadas do modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinamento do modelo com Transfer Learning\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
    "\n",
    "# Avaliação do modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c63586a-0ad2-4236-95b7-1d916eebf461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'inverse_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m new_image_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://photos.enjoei.com.br/cadeira-alimentacao-feed-safety-first-estofado-novo-97365579/800x800/czM6Ly9waG90b3MuZW5qb2VpLmNvbS5ici9wcm9kdWN0cy81MjczNTc5LzYzMTgwMGY1MWQxYzM2MzQ0N2EwZDlkZDg4YWU5YTQ5LmpwZw\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Classificação da nova imagem\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m predicted_category, probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_image_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_image_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA nova imagem pertence à categoria: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_category\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbabilidades de cada classe: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprobabilities\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m, in \u001b[0;36mpredict_image_category\u001b[0;34m(image_url)\u001b[0m\n\u001b[1;32m     15\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(img_array)\n\u001b[1;32m     16\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m([predicted_class])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_label)\n\u001b[1;32m     19\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m prediction[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'inverse_transform'"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "# Função para carregar e pré-processar a nova imagem\n",
    "def load_and_preprocess_image(image_url, target_size=(224, 224)):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content)).resize(target_size)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img_array = np.array(img) / 255.0  # Normalize para [0, 1]\n",
    "    return np.expand_dims(img_array, axis=0)  # Adiciona uma dimensão extra para batch\n",
    "\n",
    "# Função para prever a classe de uma nova imagem\n",
    "def predict_image_category(image_url):\n",
    "    img_array = load_and_preprocess_image(image_url)\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class])[0]\n",
    "    print(predicted_label)\n",
    "    probabilities = prediction[0]\n",
    "    # Converter as probabilidades em porcentagens\n",
    "    probabilities_percent = np.max(prediction) * 100\n",
    "    return predicted_label, probabilities_percent\n",
    "\n",
    "# URL da nova imagem para classificação\n",
    "new_image_url = \"https://photos.enjoei.com.br/cadeira-alimentacao-feed-safety-first-estofado-novo-97365579/800x800/czM6Ly9waG90b3MuZW5qb2VpLmNvbS5ici9wcm9kdWN0cy81MjczNTc5LzYzMTgwMGY1MWQxYzM2MzQ0N2EwZDlkZDg4YWU5YTQ5LmpwZw\"\n",
    "\n",
    "# Classificação da nova imagem\n",
    "predicted_category, probabilities = predict_image_category(new_image_url)\n",
    "print(f'A nova imagem pertence à categoria: {predicted_category}')\n",
    "print(f'Probabilidades de cada classe: {probabilities}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2cac5-0d6c-4237-833c-9a0c7b22af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07e5a50-0214-4a57-8059-de9a1645714f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 10:00:30.765068: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-06-27 10:00:30.765089: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: eduardo-ubuntu\n",
      "2024-06-27 10:00:30.765094: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: eduardo-ubuntu\n",
      "2024-06-27 10:00:30.765164: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 535.183.1\n",
      "2024-06-27 10:00:30.765178: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: 535.171.4\n",
      "2024-06-27 10:00:30.765182: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:251] kernel version 535.171.4 does not match DSO version 535.183.1 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./model1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf352b1-7668-4099-a074-c82c7749e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = joblib.load(\"modelo_treinado_joblib.sav\")\n",
    "print(label_encoder.in)\n",
    "num_classes = len(np.unique(encoded_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b0a35-cf66-478a-b9b9-f2fb248341be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a8fb6-11fb-4009-b5b0-1cebe6f122aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_joblib = \"modelo_treinado_joblib.sav\"\n",
    "joblib.dump(encoded_labels, arquivo_joblib)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
